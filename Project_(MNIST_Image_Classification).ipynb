{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project (MNIST Image Classification).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMRnTtUsmYslJpNcLpD/YkN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/klimanyusuf/Comcast-Telecom-Costumer-Complain-Analysis/blob/master/Project_(MNIST_Image_Classification).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IxCYRJm5vwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QjyJQLs9Hj6L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "outputId": "ae358e50-2607-4358-c077-00caeb0d4ec6"
      },
      "source": [
        "# installing the previous version of tensor flow to carry one with the code\n",
        "!pip install tensorflow==1.12.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 66kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.30.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.34.2)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0) (47.3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.1.0)\n",
            "Installing collected packages: tensorboard, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed tensorboard-1.12.2 tensorflow-1.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIL40PSm53g8",
        "colab_type": "text"
      },
      "source": [
        "DESCRIPTION\n",
        "\n",
        "The MNIST dataset is widely used for image classification. However, while validating the same, researchers found out that the classification model was overfitting as it was not giving acceptable accuracy on the testing data. Use the mnist_test.csv and mnist_train.csv for model optimization (using dropout layers). Also, you will have to use one hot encoding for training and testing labels.\n",
        "\n",
        "Objective:\n",
        "Optimize a neural network based classification model using dropout regularization such that the p value is 0.70 for input and hidden layers.\n",
        "\n",
        "To download the datasets click here. https://www.dropbox.com/sh/8o505yi1aqsljv6/AAAk38tACJ16UZxYXZ17U1gra?dl=0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA0WgDGm6TsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "db5f249c-2b94-4664-8cfc-0fff5972f40c"
      },
      "source": [
        " import numpy as np\n",
        "import random\n",
        "input_nodes = 9\n",
        "hidden_nodes = 4\n",
        "output_nodes = 6\n",
        "wei_inp_hid = np.random.randint(-10, 10, (hidden_nodes, input_nodes))\n",
        "wei_inp_hid"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  2,   8,  -9, -10,  -5,  -8,   4,   9,   5],\n",
              "       [  7,  -7,  -6,   7,  -9,   8,  -8,   9,  -1],\n",
              "       [ -7,  -8,  -8,   1,   2,   1,   9,  -1,   0],\n",
              "       [  4,  -1,   1,   5,   0,  -9,   1,   4,  -7]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HfMUlDu7Kq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "966f5998-c511-4c37-f254-f0e216da9e4c"
      },
      "source": [
        "active_input_percentage = 0.6\n",
        "active_input_nodes = int(input_nodes * active_input_percentage)\n",
        "active_input_indices = sorted(random.sample(range(0, input_nodes), \n",
        "                              active_input_nodes))\n",
        "active_input_indices"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 5, 6, 7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO8hVxTN7lg6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "4efdcdee-c139-4180-ccb8-86e9071e7050"
      },
      "source": [
        "wei_inp_hid_old = wei_inp_hid.copy()\n",
        "wei_inp_hid = wei_inp_hid[:, active_input_indices]\n",
        "wei_inp_hid"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2,  8, -8,  4,  9],\n",
              "       [ 7, -7,  8, -8,  9],\n",
              "       [-7, -8,  1,  9, -1],\n",
              "       [ 4, -1, -9,  1,  4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msfcYw-i7qXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "c95f3733-21af-49c6-be81-8dbcb9a5afe0"
      },
      "source": [
        "wei_hid_out = np.random.randint(-10, 10, (output_nodes, hidden_nodes))\n",
        "print(wei_hid_out)\n",
        "active_hidden_percentage = 0.7\n",
        "active_hidden_nodes = int(hidden_nodes * active_hidden_percentage)\n",
        "active_hidden_indices = sorted(random.sample(range(0, hidden_nodes), \n",
        "                             active_hidden_nodes))\n",
        "print(active_hidden_indices)\n",
        "wei_hid_out_old = wei_hid_out.copy()\n",
        "wei_hid_out = wei_hid_out[:, active_hidden_indices]\n",
        "print(wei_hid_out)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   1  -4  -2]\n",
            " [  9  -9 -10   7]\n",
            " [ -5 -10  -6   4]\n",
            " [-10   6  -2  -6]\n",
            " [  4  -9  -7   0]\n",
            " [  2   1   6  -6]]\n",
            "[0, 1]\n",
            "[[  0   1]\n",
            " [  9  -9]\n",
            " [ -5 -10]\n",
            " [-10   6]\n",
            " [  4  -9]\n",
            " [  2   1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpYY0GMr8T__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "35eaef47-06b5-4a6a-b710-f678e10f3f31"
      },
      "source": [
        "wei_inp_hid = wei_inp_hid[active_hidden_indices]\n",
        "wei_inp_hid"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2,  8, -8,  4,  9],\n",
              "       [ 7, -7,  8, -8,  9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ldct3Ekz8e6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "outputId": "77f1fe2e-fa20-4c70-9eb2-9c57884243a4"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "input_nodes = 10\n",
        "hidden_nodes = 5\n",
        "output_nodes = 7\n",
        "wei_inp_hid = np.random.randint(-10, 10, (hidden_nodes, input_nodes))\n",
        "print(\"wei_inp_hid: \\n\", wei_inp_hid)\n",
        "wei_hid_out = np.random.randint(-10, 10, (output_nodes, hidden_nodes))\n",
        "print(\"wei_hid_out:\\n\", wei_hid_out)\n",
        "active_input_percentage = 0.7\n",
        "active_hidden_percentage = 0.7\n",
        "active_input_nodes = int(input_nodes * active_input_percentage)\n",
        "active_input_indices = sorted(random.sample(range(0, input_nodes), \n",
        "                              active_input_nodes))\n",
        "print(\"\\nactive input indices: \", active_input_indices)\n",
        "active_hidden_nodes = int(hidden_nodes * active_hidden_percentage)\n",
        "active_hidden_indices = sorted(random.sample(range(0, hidden_nodes), \n",
        "                             active_hidden_nodes))\n",
        "print(\"active hidden indices: \", active_hidden_indices)\n",
        "wei_inp_hid_old = wei_inp_hid.copy()\n",
        "wei_inp_hid = wei_inp_hid[:, active_input_indices]\n",
        "print(\"\\nweight_input_hidden after deactivating input nodes:\\n\", wei_inp_hid)\n",
        "wei_inp_hid = wei_inp_hid[active_hidden_indices]\n",
        "print(\"\\nweight_input_hidden after deactivating hidden nodes:\\n\", wei_inp_hid)\n",
        "wei_hid_out_old = wei_hid_out.copy()\n",
        "wei_hid_out = wei_hid_out[:, active_hidden_indices]\n",
        "print(\"\\nweight_output_hidden after deactivating hidden nodes:\\n\", wei_hid_out)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wei_inp_hid: \n",
            " [[  5  -3  -1  -1  -9  -7   4   8   1   1]\n",
            " [-10  -3  -3   3   2   7   9   5  -4   1]\n",
            " [  6   8   0   8   3   0   6   4   6   4]\n",
            " [ -2   3  -3  -1   3   7   8   8   8  -8]\n",
            " [  7   2  -4 -10  -8   0   0   3   4  -6]]\n",
            "wei_hid_out:\n",
            " [[-1  9  0  1 -4]\n",
            " [-9  2 -1  9 -3]\n",
            " [ 9  0  9  8 -7]\n",
            " [ 8  3  9  6  0]\n",
            " [ 5 -8  8 -6 -4]\n",
            " [ 1 -3 -1 -8 -4]\n",
            " [ 6  4 -5  6 -6]]\n",
            "\n",
            "active input indices:  [0, 1, 2, 4, 5, 8, 9]\n",
            "active hidden indices:  [1, 2, 3]\n",
            "\n",
            "weight_input_hidden after deactivating input nodes:\n",
            " [[  5  -3  -1  -9  -7   1   1]\n",
            " [-10  -3  -3   2   7  -4   1]\n",
            " [  6   8   0   3   0   6   4]\n",
            " [ -2   3  -3   3   7   8  -8]\n",
            " [  7   2  -4  -8   0   4  -6]]\n",
            "\n",
            "weight_input_hidden after deactivating hidden nodes:\n",
            " [[-10  -3  -3   2   7  -4   1]\n",
            " [  6   8   0   3   0   6   4]\n",
            " [ -2   3  -3   3   7   8  -8]]\n",
            "\n",
            "weight_output_hidden after deactivating hidden nodes:\n",
            " [[ 9  0  1]\n",
            " [ 2 -1  9]\n",
            " [ 0  9  8]\n",
            " [ 3  9  6]\n",
            " [-8  8 -6]\n",
            " [-3 -1 -8]\n",
            " [ 4 -5  6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oKNVARk8xJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from scipy.special import expit as activation_function\n",
        "from scipy.stats import truncnorm\n",
        "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
        "    return truncnorm(\n",
        "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
        "class NeuralNetwork:\n",
        "    \n",
        "    def __init__(self, \n",
        "                 no_of_in_nodes, \n",
        "                 no_of_out_nodes, \n",
        "                 no_of_hidden_nodes,\n",
        "                 learning_rate,\n",
        "                 bias=None\n",
        "                ):  \n",
        "        self.no_of_in_nodes = no_of_in_nodes\n",
        "        self.no_of_out_nodes = no_of_out_nodes       \n",
        "        self.no_of_hidden_nodes = no_of_hidden_nodes          \n",
        "        self.learning_rate = learning_rate \n",
        "        self.bias = bias\n",
        "        self.create_weight_matrices()\n",
        "        \n",
        "    def create_weight_matrices(self):\n",
        "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
        "        \n",
        "        bias_node = 1 if self.bias else 0\n",
        "        n = (self.no_of_in_nodes + bias_node) * self.no_of_hidden_nodes\n",
        "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
        "        self.wei_inp_hid = X.rvs(n).reshape((self.no_of_hidden_nodes, \n",
        "                                                   self.no_of_in_nodes + bias_node))\n",
        "        n = (self.no_of_hidden_nodes + bias_node) * self.no_of_out_nodes\n",
        "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
        "        self.wei_hid_out = X.rvs(n).reshape((self.no_of_out_nodes, \n",
        "                                                    (self.no_of_hidden_nodes + bias_node)))\n",
        "    def dropout_weight_matrices(self,\n",
        "                                active_input_percentage=0.70,\n",
        "                                active_hidden_percentage=0.70):\n",
        "        # restore wei_inp_hid array, if it had been used for dropout\n",
        "        self.wei_inp_hid_orig = self.wei_inp_hid.copy()\n",
        "        self.no_of_in_nodes_orig = self.no_of_in_nodes\n",
        "        self.no_of_hidden_nodes_orig = self.no_of_hidden_nodes\n",
        "        self.wei_hid_out_orig = self.wei_hid_out.copy()\n",
        "        \n",
        "        active_input_nodes = int(self.no_of_in_nodes * active_input_percentage)\n",
        "        active_input_indices = sorted(random.sample(range(0, self.no_of_in_nodes), \n",
        "                                      active_input_nodes))\n",
        "        active_hidden_nodes = int(self.no_of_hidden_nodes * active_hidden_percentage)\n",
        "        active_hidden_indices = sorted(random.sample(range(0, self.no_of_hidden_nodes), \n",
        "                                       active_hidden_nodes))\n",
        "        \n",
        "        self.wei_inp_hid = self.wei_inp_hid[:, active_input_indices][active_hidden_indices]       \n",
        "        self.wei_hid_out = self.wei_hid_out[:, active_hidden_indices]\n",
        "        \n",
        "        self.no_of_hidden_nodes = active_hidden_nodes\n",
        "        self.no_of_in_nodes = active_input_nodes\n",
        "        return active_input_indices, active_hidden_indices\n",
        "    \n",
        "    def weight_matrices_reset(self, \n",
        "                              active_input_indices, \n",
        "                              active_hidden_indices):\n",
        "        \n",
        "        \"\"\"\n",
        "        self.wei_inp_hid and self.wei_hid_out contain the newly adapted values from the active nodes.\n",
        "        We have to reconstruct the original weight matrices by assigning the new values \n",
        "        from the active nodes\n",
        "        \"\"\"\n",
        " \n",
        "        temp = self.wei_inp_hid_orig.copy()[:,active_input_indices]\n",
        "        temp[active_hidden_indices] = self.wei_inp_hid\n",
        "        self.wei_inp_hid_orig[:, active_input_indices] = temp\n",
        "        self.wei_inp_hid = self.wei_inp_hid_orig.copy()\n",
        "        self.wei_hid_out_orig[:, active_hidden_indices] = self.wei_hid_out\n",
        "        self.wei_hid_out = self.wei_hid_out_orig.copy()\n",
        "        self.no_of_in_nodes = self.no_of_in_nodes_orig\n",
        "        self.no_of_hidden_nodes = self.no_of_hidden_nodes_orig\n",
        " \n",
        "           \n",
        "    \n",
        "    def train_single(self, input_vector, target_vector):\n",
        "        \"\"\" \n",
        "        input_vector and target_vector can be tuple, list or ndarray\n",
        "        \"\"\"\n",
        " \n",
        "        if self.bias:\n",
        "            # adding bias node to the end of the input_vector\n",
        "            input_vector = np.concatenate( (input_vector, [self.bias]) )\n",
        "        input_vector = np.array(input_vector, ndmin=2).T\n",
        "        target_vector = np.array(target_vector, ndmin=2).T\n",
        "        output_vector1 = np.dot(self.wei_inp_hid, input_vector)\n",
        "        output_vector_hidden = activation_function(output_vector1)\n",
        "        \n",
        "        if self.bias:\n",
        "            output_vector_hidden = np.concatenate( (output_vector_hidden, [[self.bias]]) )\n",
        "        \n",
        "        output_vector2 = np.dot(self.wei_hid_out, output_vector_hidden)\n",
        "        output_vector_network = activation_function(output_vector2)\n",
        "        \n",
        "        output_errors = target_vector - output_vector_network\n",
        "        # update the weights:\n",
        "        tmp = output_errors * output_vector_network * (1.0 - output_vector_network)     \n",
        "        tmp = self.learning_rate  * np.dot(tmp, output_vector_hidden.T)\n",
        "        self.wei_hid_out += tmp\n",
        "        # calculate hidden errors:\n",
        "        hidden_errors = np.dot(self.wei_hid_out.T, output_errors)\n",
        "        # update the weights:\n",
        "        tmp = hidden_errors * output_vector_hidden * (1.0 - output_vector_hidden)\n",
        "        if self.bias:\n",
        "            x = np.dot(tmp, input_vector.T)[:-1,:] \n",
        "        else:\n",
        "            x = np.dot(tmp, input_vector.T)\n",
        "        self.wei_inp_hid += self.learning_rate * x\n",
        "            \n",
        "        \n",
        "    def train(self, data_array, \n",
        "              labels_one_hot_array,\n",
        "              epochs=1,\n",
        "              active_input_percentage=0.70,\n",
        "              active_hidden_percentage=0.70,\n",
        "              no_of_dropout_tests = 10):\n",
        "        partition_length = int(len(data_array) / no_of_dropout_tests)\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            print(\"epoch: \", epoch)\n",
        "            for start in range(0, len(data_array), partition_length):\n",
        "                active_in_indices, active_hidden_indices = \\\n",
        "                           self.dropout_weight_matrices(active_input_percentage,\n",
        "                                                        active_hidden_percentage)\n",
        "                for i in range(start, start + partition_length):\n",
        "                    self.train_single(data_array[i][active_in_indices], \n",
        "                                     labels_one_hot_array[i]) \n",
        "                    \n",
        "                self.weight_matrices_reset(active_in_indices, active_hidden_indices)\n",
        "      \n",
        "    \n",
        "    def confusion_matrix(self, data_array, labels):\n",
        "        cm = {}\n",
        "        for i in range(len(data_array)):\n",
        "            res = self.run(data_array[i])\n",
        "            res_max = res.argmax()\n",
        "            target = labels[i][0]\n",
        "            if (target, res_max) in cm:\n",
        "                cm[(target, res_max)] += 1\n",
        "            else:\n",
        "                cm[(target, res_max)] = 1\n",
        "        return cm\n",
        "        \n",
        "    \n",
        "    def run(self, input_vector):\n",
        "        # input_vector can be tuple, list or ndarray\n",
        "        \n",
        "        if self.bias:\n",
        "            # adding bias node to the end of the input_vector\n",
        "            input_vector = np.concatenate( (input_vector, [self.bias]) )\n",
        "        input_vector = np.array(input_vector, ndmin=2).T\n",
        "        output_vector = np.dot(self.wei_inp_hid, input_vector)\n",
        "        output_vector = activation_function(output_vector)\n",
        "        \n",
        "        if self.bias:\n",
        "            output_vector = np.concatenate( (output_vector, [[self.bias]]) )\n",
        "            \n",
        "        output_vector = np.dot(self.wei_hid_out, output_vector)\n",
        "        output_vector = activation_function(output_vector)\n",
        "    \n",
        "        return output_vector\n",
        "    \n",
        "    \n",
        "    def evaluate(self, data, labels):\n",
        "        corrects, wrongs = 0, 0\n",
        "        for i in range(len(data)):\n",
        "            res = self.run(data[i])\n",
        "            res_max = res.argmax()\n",
        "            if res_max == labels[i]:\n",
        "                corrects += 1\n",
        "            else:\n",
        "                wrongs += 1\n",
        "        return corrects, wrongs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s96iOQC89jwl",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "ab907068-69c2-49c0-e5b2-a3406d2f348f"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f270401d-6d01-42be-85b3-e8d48644dd17\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f270401d-6d01-42be-85b3-e8d48644dd17\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving mnist_test.csv to mnist_test.csv\n",
            "Saving mnist_train.csv to mnist_train.csv\n",
            "User uploaded file \"mnist_test.csv\" with length 18289443 bytes\n",
            "User uploaded file \"mnist_train.csv\" with length 109575994 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPaZ8hMC843k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "5b1ba055-4204-4b70-cc1a-38474569c824"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "image_size = 28 # width and length\n",
        "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
        "image_pixels = image_size * image_size\n",
        "train_data = np.loadtxt(\"mnist_train.csv\", \n",
        "                        delimiter=\",\")\n",
        "test_data = np.loadtxt(\"mnist_test.csv\", \n",
        "                       delimiter=\",\") \n",
        "test_data[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7., 0., 0., ..., 0., 0., 0.],\n",
              "       [2., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [9., 0., 0., ..., 0., 0., 0.],\n",
              "       [5., 0., 0., ..., 0., 0., 0.],\n",
              "       [9., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByMuYehoGOmG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7364f5e4-6414-436c-8fe5-e8cfc85c2cf9"
      },
      "source": [
        "test_data[test_data==255]\n",
        "test_data.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojyC7UbeGU6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fac = 0.99 / 255\n",
        "train_imgs = np.asfarray(train_data[:, 1:]) * fac + 0.01\n",
        "test_imgs = np.asfarray(test_data[:, 1:]) * fac + 0.01\n",
        "train_labels = np.asfarray(train_data[:, :1])\n",
        "test_labels = np.asfarray(test_data[:, :1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsMedHQqGc2G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "06bae01f-0249-43fb-faa1-2649e85e8b2e"
      },
      "source": [
        "import numpy as np\n",
        "lr = np.arange(10)\n",
        "for label in range(10):\n",
        "    one_hot = (lr==label).astype(np.int)\n",
        "    print(\"label: \", label, \" in one-hot representation: \", one_hot)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label:  0  in one-hot representation:  [1 0 0 0 0 0 0 0 0 0]\n",
            "label:  1  in one-hot representation:  [0 1 0 0 0 0 0 0 0 0]\n",
            "label:  2  in one-hot representation:  [0 0 1 0 0 0 0 0 0 0]\n",
            "label:  3  in one-hot representation:  [0 0 0 1 0 0 0 0 0 0]\n",
            "label:  4  in one-hot representation:  [0 0 0 0 1 0 0 0 0 0]\n",
            "label:  5  in one-hot representation:  [0 0 0 0 0 1 0 0 0 0]\n",
            "label:  6  in one-hot representation:  [0 0 0 0 0 0 1 0 0 0]\n",
            "label:  7  in one-hot representation:  [0 0 0 0 0 0 0 1 0 0]\n",
            "label:  8  in one-hot representation:  [0 0 0 0 0 0 0 0 1 0]\n",
            "label:  9  in one-hot representation:  [0 0 0 0 0 0 0 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG5ysEakGyuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = np.arange(no_of_different_labels)\n",
        "# transform labels into one hot representation\n",
        "train_labels_one_hot = (lr==train_labels).astype(np.float)\n",
        "test_labels_one_hot = (lr==test_labels).astype(np.float)\n",
        "# we don't want zeroes and ones in the labels neither:\n",
        "train_labels_one_hot[train_labels_one_hot==0] = 0.01\n",
        "train_labels_one_hot[train_labels_one_hot==1] = 0.99\n",
        "test_labels_one_hot[test_labels_one_hot==0] = 0.01\n",
        "test_labels_one_hot[test_labels_one_hot==1] = 0.99"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTQoySsmG8V_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 28 # width and length\n",
        "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
        "image_pixels = image_size * image_size"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu8ubknlG-8M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "dd35fa5a-efcc-42c1-caa8-71885a0466b3"
      },
      "source": [
        "parts = 10\n",
        "partition_length = int(len(train_imgs) / parts)\n",
        "print(partition_length)\n",
        "start = 0\n",
        "for start in range(0, len(train_imgs), partition_length):\n",
        "    print(start, start + partition_length)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6000\n",
            "0 6000\n",
            "6000 12000\n",
            "12000 18000\n",
            "18000 24000\n",
            "24000 30000\n",
            "30000 36000\n",
            "36000 42000\n",
            "42000 48000\n",
            "48000 54000\n",
            "54000 60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMm0eq6uHTn8",
        "colab_type": "text"
      },
      "source": [
        "Training NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JJcdSjdHNyV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "11a7cd07-3bfc-42ad-9880-87db563a2c8a"
      },
      "source": [
        "epochs = 3\n",
        "simple_network = NeuralNetwork(no_of_in_nodes = image_pixels, \n",
        "                               no_of_out_nodes = 10, \n",
        "                               no_of_hidden_nodes = 100,\n",
        "                               learning_rate = 0.1)\n",
        "    \n",
        "    \n",
        " \n",
        "simple_network.train(train_imgs, \n",
        "                     train_labels_one_hot, \n",
        "                     active_input_percentage=1,\n",
        "                     active_hidden_percentage=1,\n",
        "                     no_of_dropout_tests = 100,\n",
        "                     epochs=epochs)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  0\n",
            "epoch:  1\n",
            "epoch:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7ezGhcDHeP1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7c70e8d3-50ca-45f8-e6ab-24adacb09a4a"
      },
      "source": [
        "corrects, wrongs = simple_network.evaluate(train_imgs, train_labels)\n",
        "print(\"accruracy train: \", corrects / ( corrects + wrongs))\n",
        "corrects, wrongs = simple_network.evaluate(test_imgs, test_labels)\n",
        "print(\"accruracy: test\", corrects / ( corrects + wrongs))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accruracy train:  0.9128833333333334\n",
            "accruracy: test 0.9084\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}